{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import heapq\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment related Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisasterZoneEnv:\n",
    "    \"\"\"\n",
    "    A 2D grid environment to simulate a disaster zone for AI agents. The environment\n",
    "    can be configured to be either static or dynamic, with the grid containing survivors,\n",
    "    resources, obstacles, and a drone.\n",
    "\n",
    "    Legend:\n",
    "        0 -> Empty cell\n",
    "        1 -> Obstacle\n",
    "        2 -> Survivor\n",
    "        3 -> Resource\n",
    "        D -> Drone (tracked separately, but displayed in render)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, width=10, height=10, num_obstacles=5, num_survivors=3, num_resources=2, initial_energy=50, dynamic=False):\n",
    "        \"\"\"\n",
    "        Initialize the environment with configurable dimensions and grid contents.\n",
    "\n",
    "        :param width: Width of the grid.\n",
    "        :param height: Height of the grid.\n",
    "        :param num_obstacles: Number of obstacles to place in the grid.\n",
    "        :param num_survivors: Number of survivors to place in the grid.\n",
    "        :param num_resources: Number of resources to place in the grid.\n",
    "        :param initial_energy: Initial energy level of the drone.\n",
    "        :param dynamic: Whether the environment is dynamic (changes during simulation).\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_obstacles = num_obstacles\n",
    "        self.num_survivors = num_survivors\n",
    "        self.num_resources = num_resources\n",
    "        self.initial_energy = initial_energy\n",
    "        self.dynamic = dynamic  # Determines whether the environment changes during simulation\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the environment to its initial state by randomly placing obstacles,\n",
    "        survivors, resources, and the drone.\n",
    "\n",
    "        :return: The initial state of the drone (position, energy).\n",
    "        \"\"\"\n",
    "        # Initialize an empty grid\n",
    "        self.grid = np.zeros((self.height, self.width), dtype=int)\n",
    "\n",
    "        # Place obstacles, survivors, and resources randomly\n",
    "        for _ in range(self.num_obstacles):\n",
    "            x, y = self._get_random_empty_cell()\n",
    "            self.grid[x, y] = 1  # Obstacle\n",
    "        for _ in range(self.num_survivors):\n",
    "            x, y = self._get_random_empty_cell()\n",
    "            self.grid[x, y] = 2  # Survivor\n",
    "        for _ in range(self.num_resources):\n",
    "            x, y = self._get_random_empty_cell()\n",
    "            self.grid[x, y] = 3  # Resource\n",
    "\n",
    "        # Place the drone at a random position\n",
    "        self.drone_x, self.drone_y = self._get_random_empty_cell()\n",
    "\n",
    "        # Set the drone's initial energy level\n",
    "        self.energy = self.initial_energy\n",
    "\n",
    "        # Return the initial state (drone position and energy)\n",
    "        return self._get_state()\n",
    "\n",
    "    def _get_random_empty_cell(self):\n",
    "        \"\"\"\n",
    "        Finds a random empty cell in the grid that is not occupied by any obstacles,\n",
    "        survivors, resources, or the drone.\n",
    "\n",
    "        :return: Coordinates (x, y) of an empty cell.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            x = random.randint(0, self.height - 1)\n",
    "            y = random.randint(0, self.width - 1)\n",
    "            if self.grid[x, y] == 0:  # Ensure the cell is empty\n",
    "                return x, y\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"\n",
    "        Returns the current state of the drone.\n",
    "\n",
    "        :return: Tuple containing the drone's position (x, y) and remaining energy.\n",
    "        \"\"\"\n",
    "        return (self.drone_x, self.drone_y, self.energy)\n",
    "\n",
    "    def step(self, x, y):\n",
    "        \"\"\"\n",
    "        Moves the drone to a specific position (x, y) on the grid.\n",
    "\n",
    "        :param x: Target x-coordinate.\n",
    "        :param y: Target y-coordinate.\n",
    "        \"\"\"\n",
    "        self.drone_x, self.drone_y = x, y\n",
    "        self.energy -= 1  # Deduct energy for the move\n",
    "\n",
    "    def apply_dynamic_changes(self, step_count):\n",
    "        \"\"\"\n",
    "        Applies dynamic changes to the grid, such as adding obstacles, moving survivors,\n",
    "        and placing new resources, based on the current step count.\n",
    "\n",
    "        :param step_count: The current simulation step.\n",
    "        \"\"\"\n",
    "        if self.dynamic:\n",
    "            # Add a new obstacle every 5 steps\n",
    "            if step_count % 5 == 0:\n",
    "                x, y = self._get_random_empty_cell()\n",
    "                self.grid[x, y] = 1  # Add an obstacle\n",
    "                print(f\"Dynamic Change: Added obstacle at ({x}, {y})\")\n",
    "\n",
    "            # Move survivors every 3 steps\n",
    "            if step_count % 3 == 0:\n",
    "                survivor_positions = [(x, y) for x in range(self.height)\n",
    "                                      for y in range(self.width) if self.grid[x, y] == 2]\n",
    "                for x, y in survivor_positions:\n",
    "                    self.grid[x, y] = 0  # Remove survivor from the current position\n",
    "                    new_x, new_y = self._get_random_empty_cell()\n",
    "                    self.grid[new_x, new_y] = 2  # Place survivor in a new position\n",
    "                    print(f\"Dynamic Change: Moved survivor from ({x}, {y}) to ({new_x}, {new_y})\")\n",
    "\n",
    "            # Add a new resource every 7 steps\n",
    "            if step_count % 7 == 0:\n",
    "                x, y = self._get_random_empty_cell()\n",
    "                self.grid[x, y] = 3  # Add a resource\n",
    "                print(f\"Dynamic Change: Added resource at ({x}, {y})\")\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Renders the current state of the grid by printing it to the console.\n",
    "        \"\"\"\n",
    "        # Copy the grid for visualization\n",
    "        grid_copy = np.copy(self.grid).astype(str)\n",
    "\n",
    "        # Replace numeric values with symbols for better readability\n",
    "        grid_copy[grid_copy == '0'] = '.'  # Empty cell\n",
    "        grid_copy[grid_copy == '1'] = '#'  # Obstacle\n",
    "        grid_copy[grid_copy == '2'] = 'S'  # Survivor\n",
    "        grid_copy[grid_copy == '3'] = 'R'  # Resource\n",
    "\n",
    "        # Place the drone in the visualization\n",
    "        grid_copy[self.drone_x, self.drone_y] = 'D'\n",
    "\n",
    "        # Print the grid row by row\n",
    "        for row in grid_copy:\n",
    "            print(\" \".join(row))\n",
    "        print(f\"Energy: {self.energy}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dijikstra Agent Related Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DijkstraAgent:\n",
    "    \"\"\"\n",
    "    An agent that uses Dijkstra's algorithm to find the shortest path\n",
    "    to the nearest target (e.g., survivor or resource) in the DisasterZoneEnv.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        Initializes the agent with the environment.\n",
    "\n",
    "        :param env: An instance of the DisasterZoneEnv class.\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "\n",
    "    def dijkstra(self, grid, start, target):\n",
    "        \"\"\"\n",
    "        Dijkstra's algorithm to find the shortest path in a 2D grid.\n",
    "\n",
    "        :param grid: The grid representing the environment.\n",
    "        :param start: The starting position of the agent (x, y).\n",
    "        :param target: The target position (x, y).\n",
    "        :return: The shortest path as a list of coordinates and the total distance.\n",
    "        \"\"\"\n",
    "        # Movement directions (up, down, left, right)\n",
    "        directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "\n",
    "        # Priority queue to store distances and positions\n",
    "        pq = [(0, start)]\n",
    "        distances = {start: 0}\n",
    "        previous = {start: None}\n",
    "\n",
    "        while pq:\n",
    "            # Get the node with the smallest distance\n",
    "            current_distance, current_position = heapq.heappop(pq)\n",
    "\n",
    "            if current_position == target:\n",
    "                # Reconstruct the path from start to target\n",
    "                path = []\n",
    "                while current_position is not None:\n",
    "                    path.append(current_position)\n",
    "                    current_position = previous[current_position]\n",
    "                path.reverse()\n",
    "                return path, current_distance\n",
    "\n",
    "            # Explore neighbors\n",
    "            for dx, dy in directions:\n",
    "                neighbor = (current_position[0] + dx, current_position[1] + dy)\n",
    "\n",
    "                if 0 <= neighbor[0] < grid.shape[0] and 0 <= neighbor[1] < grid.shape[1] and grid[neighbor[0], neighbor[1]] != 1:\n",
    "                    new_distance = current_distance + 1\n",
    "                    if neighbor not in distances or new_distance < distances[neighbor]:\n",
    "                        distances[neighbor] = new_distance\n",
    "                        previous[neighbor] = current_position\n",
    "                        heapq.heappush(pq, (new_distance, neighbor))\n",
    "\n",
    "        return [], float('inf')  # Return an empty path if the target is unreachable\n",
    "\n",
    "    def find_closest_target(self, target_type):\n",
    "        \"\"\"\n",
    "        Finds the closest target of a given type (survivor or resource).\n",
    "\n",
    "        :param target_type: The type of target to find (2 for survivor, 3 for resource).\n",
    "        :return: The shortest path to the closest target and the target position.\n",
    "        \"\"\"\n",
    "        start = (self.env.drone_x, self.env.drone_y)\n",
    "        targets = [(x, y) for x in range(self.env.height) for y in range(self.env.width) if self.env.grid[x, y] == target_type]\n",
    "\n",
    "        if not targets:\n",
    "            return None, None, float('inf')  # No targets available\n",
    "\n",
    "        shortest_path, closest_target, shortest_distance = None, None, float('inf')\n",
    "        for target in targets:\n",
    "            path, distance = self.dijkstra(self.env.grid, start, target)\n",
    "            if path and distance < shortest_distance:  # Ensure path exists\n",
    "                shortest_path, closest_target, shortest_distance = path, target, distance\n",
    "\n",
    "        # If no reachable targets, return None\n",
    "        if shortest_distance == float('inf'):\n",
    "            print(f\"No reachable targets of type {target_type}.\")\n",
    "            return None, None, float('inf')\n",
    "\n",
    "        return shortest_path, closest_target, shortest_distance\n",
    "\n",
    "\n",
    "\n",
    "    def execute(self, dynamic=False, step_limit=500):\n",
    "        \"\"\"\n",
    "        The main loop of the Dijkstra Agent. Finds and moves to targets (survivors and resources)\n",
    "        until the agent runs out of energy, there are no more targets, or a step limit is reached.\n",
    "\n",
    "        :param dynamic: Whether to apply dynamic changes to the environment.\n",
    "        :param step_limit: The maximum number of steps before stopping.\n",
    "        :return: Total number of cells explored during the simulation.\n",
    "        \"\"\"\n",
    "        step_count = 0\n",
    "        self.cells_explored = 0  # Reset cells explored counter\n",
    "\n",
    "        while self.env.energy > 0 and step_count < step_limit:\n",
    "            if dynamic:\n",
    "                self.env.apply_dynamic_changes(step_count)\n",
    "\n",
    "            # Find the closest survivor first, then resources\n",
    "            path, target_position, distance = self.find_closest_target(2)  # Try to find survivors\n",
    "            if not path:\n",
    "                path, target_position, distance = self.find_closest_target(3)  # Try to find resources\n",
    "\n",
    "            # If no targets are reachable, stop the simulation\n",
    "            if not path:\n",
    "                print(\"No reachable targets remaining. Stopping simulation.\")\n",
    "                break\n",
    "\n",
    "            # Move the drone along the computed path\n",
    "            for step in path[1:]:  # Skip the starting position\n",
    "                self.env.step(*step)\n",
    "                step_count += 1\n",
    "\n",
    "                # Optional: Only render every 5 steps for better performance\n",
    "                if step_count % 5 == 0:\n",
    "                    self.env.render()\n",
    "\n",
    "                if dynamic:\n",
    "                    self.env.apply_dynamic_changes(step_count)\n",
    "\n",
    "                # Stop if energy is exhausted\n",
    "                if self.env.energy <= 0:\n",
    "                    print(\"Drone ran out of energy!\")\n",
    "                    break\n",
    "\n",
    "            # Stop if step limit is reached\n",
    "            if step_count >= step_limit:\n",
    "                print(\"Step limit reached. Stopping simulation.\")\n",
    "                break\n",
    "\n",
    "        print(\"Agent has completed its task.\")\n",
    "        return self.cells_explored  # Return total cells explored\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester Related Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    \"\"\"\n",
    "    A generalized testing framework for evaluating AI agents in the DisasterZoneEnv.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, num_tests=5, verbose=True):\n",
    "        \"\"\"\n",
    "        Initialize the testing framework.\n",
    "\n",
    "        :param env: The DisasterZoneEnv instance.\n",
    "        :param num_tests: Number of test runs.\n",
    "        :param verbose: Whether to print detailed logs.\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        self.num_tests = num_tests\n",
    "        self.verbose = verbose\n",
    "        self.results = []  # Store results for all tests\n",
    "\n",
    "    def run(self, agent_class, dynamic=False, step_limit=500):\n",
    "        \"\"\"\n",
    "        Run tests for the specified agent and record metrics.\n",
    "\n",
    "        :param agent_class: The agent class to test (e.g., DijkstraAgent).\n",
    "        :param dynamic: Whether to enable dynamic changes in the environment.\n",
    "        :param step_limit: Maximum steps per test.\n",
    "        \"\"\"\n",
    "        for test_idx in range(self.num_tests):\n",
    "            # Reset the environment for each test\n",
    "            self.env.reset()\n",
    "            agent = agent_class(self.env)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"\\n=== Test {test_idx + 1}/{self.num_tests} ===\")\n",
    "            \n",
    "            # Start tracking metrics\n",
    "            initial_survivors = np.sum(self.env.grid == 2)  # Count initial survivors\n",
    "            initial_resources = np.sum(self.env.grid == 3)  # Count initial resources\n",
    "            initial_energy = self.env.energy\n",
    "\n",
    "            # Run the agent in the environment\n",
    "            steps_explored = agent.execute(dynamic=dynamic, step_limit=step_limit)\n",
    "\n",
    "            # Calculate results\n",
    "            survivors_left = np.sum(self.env.grid == 2)  # Survivors left\n",
    "            resources_left = np.sum(self.env.grid == 3)  # Resources left\n",
    "\n",
    "            survivors_rescued = initial_survivors - survivors_left\n",
    "            resources_collected = initial_resources - resources_left\n",
    "            energy_used = initial_energy - self.env.energy\n",
    "\n",
    "            # Add test results to the results list\n",
    "            self.results.append({\n",
    "                \"Test\": test_idx + 1,\n",
    "                \"Dynamic\": dynamic,\n",
    "                \"Survivors Rescued\": survivors_rescued,\n",
    "                \"Resources Collected\": resources_collected,\n",
    "                \"Energy Used\": energy_used,\n",
    "                \"Steps Explored\": steps_explored,\n",
    "            })\n",
    "\n",
    "            # Print results for the test if verbose is enabled\n",
    "            if self.verbose:\n",
    "                print(f\"Survivors Rescued: {survivors_rescued}\")\n",
    "                print(f\"Resources Collected: {resources_collected}\")\n",
    "                print(f\"Energy Used: {energy_used}\")\n",
    "                print(f\"Steps Explored: {steps_explored}\")\n",
    "\n",
    "\n",
    "    def display_results(self):\n",
    "        \"\"\"\n",
    "        Displays the collected test results in a table format using pandas.\n",
    "        \"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results to display.\")\n",
    "            return\n",
    "\n",
    "        # Convert results to a pandas DataFrame for tabular output\n",
    "        df = pd.DataFrame(self.results)\n",
    "        print(\"\\n=== Results Table ===\")\n",
    "        print(df)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code for Runinng Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STATIC ENVIRONMENT TEST ===\n",
      "\n",
      "=== Test 1/3 ===\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Static Environment Test\n",
    "    print(\"\\n=== STATIC ENVIRONMENT TEST ===\")\n",
    "    static_env = DisasterZoneEnv(\n",
    "        width=10, height=10, \n",
    "        num_obstacles=8, num_survivors=5, num_resources=2, \n",
    "        initial_energy=20, dynamic=False\n",
    "    )\n",
    "    static_tester = Tester(static_env, num_tests=3, verbose=True)\n",
    "    static_tester.run(agent_class=DijkstraAgent, dynamic=False)\n",
    "    static_results = static_tester.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST449",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
